{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26feea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge, LinearRegression, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, RepeatedKFold, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dc5f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "data = pd.read_excel('Inputs and Outputs.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabcb05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into train and test\n",
    "\n",
    "X_train = data.iloc[0:10, 0:5]\n",
    "Y_train = data.iloc[0:10, 5:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e058e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data.iloc[10:, 0:5]\n",
    "Y_test = data.iloc[10:, 5:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012aad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate algorithms\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LinearRegression()))\n",
    "models.append(('R', Ridge()))\n",
    "models.append(('LASSO', Lasso()))\n",
    "models.append(('EN', ElasticNet()))\n",
    "models.append(('KNN', KNeighborsRegressor()))\n",
    "models.append(('CART', DecisionTreeRegressor()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e942ae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate each model in turn\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "scoring='neg_mean_absolute_error'\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6d0ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate algorithms on standardize dataset\n",
    "\n",
    "pipelines = []\n",
    "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('LR', LinearRegression())])))\n",
    "pipelines.append(('ScaledR', Pipeline([('Scaler', StandardScaler()),('R', Ridge())])))\n",
    "pipelines.append(('ScaledLASSO', Pipeline([('Scaler', StandardScaler()),('LASSO', Lasso())])))\n",
    "pipelines.append(('ScaledEN', Pipeline([('Scaler', StandardScaler()),('EN', ElasticNet())])))\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsRegressor())])))\n",
    "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART', DecisionTreeRegressor())])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f8ec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate each model in turn\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "scoring='neg_mean_absolute_error'\n",
    "\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f7d92e",
   "metadata": {},
   "source": [
    "The best performing algorithm is Lasso Regressor on a standardized dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179cdea6",
   "metadata": {},
   "source": [
    "#### Tune Lasso Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be22600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "\n",
    "model = Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c249bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# define grid\n",
    "grid = dict()\n",
    "grid['alpha'] = np.arange(0, 1, 0.01)\n",
    "\n",
    "# define search\n",
    "search = GridSearchCV(model, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "# perform the search\n",
    "sc = StandardScaler()\n",
    "X_scaled = sc.fit_transform(X_train)\n",
    "results = search.fit(X_scaled, Y_train)\n",
    "\n",
    "# summarize\n",
    "print('MAE: %.3f' % results.best_score_)\n",
    "print('Config: %s' % results.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb2ec24",
   "metadata": {},
   "source": [
    "#### Build Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62039f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing a scaler\n",
    "\n",
    "scaler = sc.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283d78d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving scaler for deployment\n",
    "\n",
    "with open('scaler_pkl', 'wb') as files:\n",
    "    pickle.dump(scaler, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff936271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform train data with scaler\n",
    "\n",
    "X_scaled = sc.transform(X_train)\n",
    "\n",
    "final_model = Lasso(alpha=0.99)\n",
    "final_model.fit(X_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a3021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save final model\n",
    "\n",
    "with open('tuned_pkl', 'wb') as files:\n",
    "    pickle.dump(final_model, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2c7099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "\n",
    "x_test_scaled = scaler.transform(X_test)\n",
    "y_pred = final_model.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50469405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance\n",
    "\n",
    "print(\"MAE\",mean_absolute_error(Y_test,y_pred))\n",
    "print(\"MSE\",mean_squared_error(Y_test,y_pred))\n",
    "print(\"RMSE\",np.sqrt(mean_squared_error(Y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b66be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_columns = ['Back Ramp', 'Centre Base', 'Front Ramp', 'Back Wall', 'Left Wall','Right Wall', 'Roof Beams', \n",
    "                'Lintel Beam', 'Door Shaft','Door Fabrication', 'Heat Shield', 'Door Surround Casting','Refractory',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5b9206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output to dataframe\n",
    "\n",
    "output_df = pd.DataFrame(y_pred, columns=pred_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277a8f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab87d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd0e859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
